model: 
  # name: SimpleMLP
  # device: cuda
  # hidden_size: [1024, 2048, 2048, 2048, 2048, 1024]
  # dropout: 0.2

  
  name: Seq2Seq
  device: cpu
  hidden_size: 512
  num_layers: 4
  dropout: 0.0

  # name: Seq2Seq
  # device: cuda
  # hidden_size: 512
  # num_layers: 3
  # dropout: 0.2

# config.yaml
data:
  train_path: /media/ssilver/UbuntuShared/data/train
  batch_size: 1
  shuffle: false
  num_workers: 1

  experimenting: 0 # set to 0 for full datasets

  train_val_split: 1.0

  coord_dims: 2
  input_timesteps: 19
  output_timesteps: 30
  features:
    lane:
      angle_filter: True # change to angle
      distance_filter: 10
      num_lanes: 20
      embedding_size: 4
      positional_embeddings: 0 # not used if embedding_size > 0
    
    # needs work
    # lane: 0 # needs work
    p_in: 0
    v_in: 0 # should be same as p_in (num agents being considered)

    # fix me: positional embeddings causing NaN loss if too large
    positional_embeddings: 0 # 3 got down to 2.6

  transforms:
    - AgentCenter
    - RandomNoise
