model: 
  # name: SimpleMLP
  # device: cuda
  # hidden_size: [1024, 2048, 2048, 2048, 2048, 1024]
  # dropout: 0.2

  
  # name: SimpleRNN
  # device: cpu
  # hidden_size: 512
  # num_layers: 4
  # dropout: 0.0

  name: Seq2Seq
  device: cuda
  hidden_size: 512
  num_layers: 5
  dropout: 0.15
  bidirectional: false

# config.yaml
data:
  xps15:
    train_path: /media/ssilver/UbuntuShared/data/train
    val_path: /media/ssilver/UbuntuShared/data/val_in
    batch_size: 3
    shuffle: false
    num_workers: 1
    train_val_split: 0.0
  y520:
    train_path: ../train/train
    val_path: ../val_in/val_in
    batch_size: 3
    shuffle: false
    num_workers: 1
    train_val_split: 0.0
  acer:
    train_path: ../train/train
    val_path: ../val_in/val_in
    batch_size: 3
    shuffle: false
    num_workers: 1
    train_val_split: 0.0

  experimenting: 0 # set to 0 for full datasets

  train_val_split: 1.0

  coord_dims: 2
  input_timesteps: 19
  output_timesteps: 30
  teacher_forcing_freq: 0
  features:
    lane:
      angle_filter: True # change to angle
      min_y_filter: -5 # 1 for no rear filter
      num_points: 100
      embedding_size: 4
      positional_embeddings: 0 # not used if embedding_size > 0
    
    # needs work
    # lane: 0 # needs work
    p_in: 0
    v_in: 0 # should be same as p_in (num agents being considered)

    # fix me: positional embeddings causing NaN loss if too large
    positional_embeddings: 0 # 3 got down to 2.6

  transforms:
    - AgentCenter
    - RandomNoise
