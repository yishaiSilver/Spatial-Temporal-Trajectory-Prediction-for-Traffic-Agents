{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This module contains the `AgentCenter` class which applies agent-centered\n",
    "transformation to the given batch data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def homogenize_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Homogenize a 2D matrix by adding a column of ones.\n",
    "\n",
    "    Args:\n",
    "        matrix (np.ndarray): 2D matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Homogenized matrix with an additional column of ones.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the original shape\n",
    "    original_shape = matrix.shape\n",
    "\n",
    "    # get the non-numerical dimensions\n",
    "    non_numerical_dims = original_shape[:-1]\n",
    "\n",
    "    # add the '1' layer/row\n",
    "    shape = non_numerical_dims + (1,)\n",
    "    ones = np.ones(shape)\n",
    "\n",
    "    homogenized_matrix = np.concatenate(\n",
    "        [matrix, ones],\n",
    "        axis=-1,\n",
    "    )\n",
    "    return homogenized_matrix\n",
    "\n",
    "\n",
    "def get_translation_matrix(positions):\n",
    "    \"\"\"\n",
    "    Gets the translation matrix for the given positions.\n",
    "    \"\"\"\n",
    "    num_timesteps = positions.shape[0]\n",
    "\n",
    "    translation_transforms = np.eye(3)[np.newaxis].repeat(num_timesteps, axis=0)\n",
    "\n",
    "    # set the translation component of the transformation matrices\n",
    "    translation_transforms[:, :2, 2] -= positions\n",
    "\n",
    "    return translation_transforms\n",
    "\n",
    "\n",
    "def get_rotation_matrix(positions):\n",
    "    \"\"\"\n",
    "    Gets the rotation matrix for the given positions.\n",
    "    \"\"\"\n",
    "    rotation_transforms = np.eye(2)\n",
    "\n",
    "    # get the angle from the target agent's first input position to the\n",
    "    # final input position\n",
    "    first_position = positions[0]\n",
    "    last_position = positions[-1]\n",
    "\n",
    "    # get the angle\n",
    "    theta = (\n",
    "        -np.arctan2(\n",
    "            last_position[1] - first_position[1],\n",
    "            last_position[0] - first_position[0],\n",
    "        )\n",
    "        + np.pi / 2\n",
    "    )\n",
    "\n",
    "    rotation_transforms[0, 0] = np.cos(theta)\n",
    "    rotation_transforms[0, 1] = -np.sin(theta)\n",
    "    rotation_transforms[1, 0] = np.sin(theta)\n",
    "    rotation_transforms[1, 1] = np.cos(theta)\n",
    "\n",
    "    return rotation_transforms\n",
    "\n",
    "\n",
    "def apply(datum):\n",
    "    \"\"\"\n",
    "    Apply agent-centered transformation to the given datum.\n",
    "\n",
    "    Args:\n",
    "        datum (dict): Dictionary representing a single data point.\n",
    "\n",
    "    Returns:\n",
    "        dict: Transformed datum with updated positions.\n",
    "    \"\"\"\n",
    "    # get all of the ids for the agents being tracked\n",
    "    # renaming due to bad naming in the dataset\n",
    "    agent_ids = datum[\"track_id\"]\n",
    "\n",
    "    # extract the agent_id from the datum\n",
    "    target_id = datum[\"agent_id\"]\n",
    "\n",
    "    # get the index of the target agent\n",
    "    agent_index = np.where(agent_ids == target_id)[0][0]\n",
    "\n",
    "    # get the input and output data\n",
    "    positions_in = np.array(datum[\"p_in\"])\n",
    "    velocities_in = np.array(datum[\"v_in\"])\n",
    "    positions_out = np.array(datum[\"p_out\"])\n",
    "    velocities_out = np.array(datum[\"v_out\"])\n",
    "\n",
    "    # FIXME:\n",
    "    # save the input length before we extend it\n",
    "    input_length = positions_in.shape[1]\n",
    "\n",
    "    # extend by the output data\n",
    "    positions = np.concatenate([positions_in, positions_out], axis=1)\n",
    "    velocities = np.concatenate([velocities_in, velocities_out], axis=1)\n",
    "\n",
    "    offsets = np.diff(positions[agent_index], axis=0)\n",
    "\n",
    "    # create a list of transformation matrices that center all points\n",
    "    # around the target agent\n",
    "    target_positions = positions[agent_index]\n",
    "\n",
    "    # Shape: (num_timesteps, 3, 3)\n",
    "    positions = positions - target_positions\n",
    "\n",
    "\n",
    "    # create the rotation transform (key difference: only one needed)\n",
    "    rotation_transforms = get_rotation_matrix(positions_in[agent_index])\n",
    "    positions = positions @ rotation_transforms\n",
    "\n",
    "    first_offset = np.array([0, 0])\n",
    "    offsets = np.vstack([first_offset, offsets])\n",
    "    offsets = offsets @ rotation_transforms\n",
    "    positions[agent_index] = offsets\n",
    "\n",
    "    p_out = positions[:, input_length:]\n",
    "\n",
    "    # TODO change this to a full revert, rather than just the translated, rotated\n",
    "    # positions\n",
    "    # cumsum\n",
    "    # p_out = np.cumsum(p_out, axis=1)\n",
    "\n",
    "    # print(positions_out)\n",
    "    # print(p_out)\n",
    "\n",
    "    # update the positions in the datum\n",
    "    datum[\"p_in\"] = positions[:, :input_length]\n",
    "    datum[\"v_in\"] = velocities[:, :input_length]\n",
    "    datum[\"p_out\"] = p_out\n",
    "    datum[\"v_out\"] = velocities[:, input_length:]\n",
    "\n",
    "    # update the prediction correction\n",
    "    datum[\"prediction_correction\"] = inverse\n",
    "\n",
    "    # get the inverses of the translation and rotation matrices\n",
    "    # translation_transforms_inv = np.linalg.inv(translation_transforms)\n",
    "    rotation_transforms_inv = np.linalg.inv(rotation_transforms)\n",
    "\n",
    "    metadata = {\n",
    "        \"target_offset\": target_positions,\n",
    "        \"rotation_transforms\": rotation_transforms_inv,\n",
    "    }\n",
    "\n",
    "    datum[\"batch_correction_metadata\"] = metadata\n",
    "\n",
    "    return datum\n",
    "\n",
    "\n",
    "def inverse(predictions, metadata):\n",
    "    \"\"\"TODO: correct_predictions\"\"\"\n",
    "\n",
    "    # IMPORTANT: inputs are batched\n",
    "\n",
    "    # NOTE: Since we have only moved the positions, we can just leave them\n",
    "    # as is for training, but we'll need to revert them back to the original\n",
    "    # positions when we test against the dataset.\n",
    "\n",
    "    # Really, this should convert all the way back to the original, global\n",
    "    # positions, but that's a bit more effor. Leaving it as a TODO for now.\n",
    "    # thought: embed metadata in the data to know how to invert it:\n",
    "    # input, output, prediction_correction, batch_correction_metadata.\n",
    "    predictions = np.cumsum(predictions, axis=0)\n",
    "\n",
    "    # get the translation and rotation matrices\n",
    "    target_positions = metadata[\"target_offset\"][18]\n",
    "    rotation_transforms = metadata[\"rotation_transforms\"]\n",
    "\n",
    "    # apply the inverse transformations\n",
    "    # (30, 3) @ (3, 3) -> (30, 3)\n",
    "    predictions = predictions @ rotation_transforms\n",
    "\n",
    "    # (30, 3) @ (3, 3) -> (30, 3)\n",
    "    predictions = predictions + target_positions\n",
    "\n",
    "    # dehomogenize the data\n",
    "    predictions = predictions[:, :2]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "    # # apply corrections needed by other transformations.\n",
    "    # return AgentCenter.prior_prediction_correction(batch_predictions, batch_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        \"\"\"TODO: init\"\"\"\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, \"*\"))\n",
    "        self.pkl_list.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"TODO: len\"\"\"\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"getitem\"\"\"\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "dataset = ArgoverseDataset(data_path=\"data/train\", transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 90310/205942 [00:10<00:12, 9097.71it/s]"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "# test loop through time\n",
    "\n",
    "for datum in tqdm.tqdm(dataset):\n",
    "    _ = apply(datum)\n",
    "\n",
    "# # using matmul for translation: 1:13, 1:14\n",
    "# # using addition for translation: 0:41, 0:33, clearly much better.\n",
    "# using non-homogenized rotation matrix: 0:23, 0:22\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 151.68348694 2466.12939453]\n",
      " [ 151.58137512 2465.3894043 ]\n",
      " [ 151.59472656 2464.39868164]\n",
      " [ 151.56767273 2463.66186523]\n",
      " [ 151.54214478 2462.75317383]]\n"
     ]
    }
   ],
   "source": [
    "datum = dataset[100]\n",
    "agent_index = np.where(datum[\"track_id\"] == datum[\"agent_id\"])[0][0]\n",
    "# print(agent_index)\n",
    "print(datum[\"p_out\"][agent_index][:5])\n",
    "\n",
    "datum_transformed = apply(datum)\n",
    "# print(datum_transformed[\"p_out\"][agent_index][:5])\n",
    "\n",
    "# print(datum_transformed[\"batch_correction_metadata\"][\"translation_transforms\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 151.68348694 2466.12939453]\n",
      " [ 151.58137512 2465.3894043 ]\n",
      " [ 151.59472656 2464.39868164]\n",
      " [ 151.56767273 2463.66186523]\n",
      " [ 151.54214478 2462.75317383]]\n"
     ]
    }
   ],
   "source": [
    "predictions = datum_transformed[\"p_out\"][agent_index]\n",
    "metadata = datum_transformed[\"batch_correction_metadata\"]\n",
    "\n",
    "print(predictions[:5])\n",
    "\n",
    "inversed = inverse(predictions, metadata)\n",
    "\n",
    "print(inversed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
