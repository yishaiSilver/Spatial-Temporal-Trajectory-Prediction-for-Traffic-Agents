{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This module contains the `AgentCenter` class which applies agent-centered\n",
    "transformation to the given batch data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def homogenize_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Homogenize a 2D matrix by adding a column of ones.\n",
    "\n",
    "    Args:\n",
    "        matrix (np.ndarray): 2D matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Homogenized matrix with an additional column of ones.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the original shape\n",
    "    original_shape = matrix.shape\n",
    "\n",
    "    # get the non-numerical dimensions\n",
    "    non_numerical_dims = original_shape[:-1]\n",
    "\n",
    "    # add the '1' layer/row\n",
    "    shape = non_numerical_dims + (1,)\n",
    "    ones = np.ones(shape)\n",
    "\n",
    "    homogenized_matrix = np.concatenate(\n",
    "        [matrix, ones],\n",
    "        axis=-1,\n",
    "    )\n",
    "    return homogenized_matrix\n",
    "\n",
    "\n",
    "def get_translation_matrix(positions):\n",
    "    \"\"\"\n",
    "    Gets the translation matrix for the given positions.\n",
    "    \"\"\"\n",
    "    num_timesteps = positions.shape[0]\n",
    "\n",
    "    translation_transforms = np.eye(3)[np.newaxis].repeat(num_timesteps, axis=0)\n",
    "\n",
    "    # set the translation component of the transformation matrices\n",
    "    translation_transforms[:, :2, 2] -= positions\n",
    "\n",
    "    return translation_transforms\n",
    "\n",
    "\n",
    "def get_rotation_matrix(positions):\n",
    "    \"\"\"\n",
    "    Gets the rotation matrix for the given positions.\n",
    "    \"\"\"\n",
    "    rotation_transforms = np.eye(3)\n",
    "\n",
    "    # get the angle from the target agent's first input position to the\n",
    "    # final input position\n",
    "    first_position = positions[0]\n",
    "    last_position = positions[-1]\n",
    "\n",
    "    # get the angle\n",
    "    theta = (\n",
    "        -np.arctan2(\n",
    "            last_position[1] - first_position[1],\n",
    "            last_position[0] - first_position[0],\n",
    "        )\n",
    "        + np.pi / 2\n",
    "    )\n",
    "\n",
    "    rotation_transforms[0, 0] = np.cos(theta)\n",
    "    rotation_transforms[0, 1] = -np.sin(theta)\n",
    "    rotation_transforms[1, 0] = np.sin(theta)\n",
    "    rotation_transforms[1, 1] = np.cos(theta)\n",
    "\n",
    "    return rotation_transforms\n",
    "\n",
    "\n",
    "def apply(datum):\n",
    "    \"\"\"\n",
    "    Apply agent-centered transformation to the given datum.\n",
    "\n",
    "    Args:\n",
    "        datum (dict): Dictionary representing a single data point.\n",
    "\n",
    "    Returns:\n",
    "        dict: Transformed datum with updated positions.\n",
    "    \"\"\"\n",
    "    # get all of the ids for the agents being tracked\n",
    "    # renaming due to bad naming in the dataset\n",
    "    agent_ids = datum[\"track_id\"]\n",
    "\n",
    "    # extract the agent_id from the datum\n",
    "    target_id = datum[\"agent_id\"]\n",
    "\n",
    "    # get the index of the target agent\n",
    "    agent_index = np.where(agent_ids == target_id)[0][0]\n",
    "\n",
    "    # get the input and output data\n",
    "    positions_in = np.array(datum[\"p_in\"])\n",
    "    velocities_in = np.array(datum[\"v_in\"])\n",
    "    positions_out = np.array(datum[\"p_out\"])\n",
    "    velocities_out = np.array(datum[\"v_out\"])\n",
    "\n",
    "    # FIXME:\n",
    "    # save the input length before we extend it\n",
    "    input_length = positions_in.shape[1]\n",
    "\n",
    "    # extend by the output data\n",
    "    positions = np.concatenate([positions_in, positions_out], axis=1)\n",
    "    velocities = np.concatenate([velocities_in, velocities_out], axis=1)\n",
    "\n",
    "    # homogenize the 2D data\n",
    "    # shape: (num_timesteps, num_agents, 3)\n",
    "    # positions_h = homogenize_matrix(positions)\n",
    "    # velocities_h = homogenize_matrix(velocities)\n",
    "\n",
    "    offsets_h = np.diff(positions[agent_index], axis=0)\n",
    "\n",
    "    # create a list of transformation matrices that center all points\n",
    "    # around the target agent\n",
    "    target_positions = positions[agent_index]\n",
    "\n",
    "    # Shape: (num_timesteps, 3, 3)\n",
    "    positions = positions - target_positions\n",
    "\n",
    "    first_offset = np.array([0, 0, 0])\n",
    "    offsets_h = np.vstack([first_offset,offsets_h])\n",
    "    offsets = offsets_h[:, :2]\n",
    "    positions[agent_index] = offsets\n",
    "\n",
    "    p_out = positions[:, input_length:]\n",
    "\n",
    "    # update the positions in the datum\n",
    "    datum[\"p_in\"] = positions[:, :input_length]\n",
    "    datum[\"v_in\"] = velocities[:, :input_length]\n",
    "    datum[\"p_out\"] = p_out\n",
    "    datum[\"v_out\"] = velocities[:, input_length:]\n",
    "\n",
    "    # update the prediction correction\n",
    "    datum[\"prediction_correction\"] = inverse\n",
    "\n",
    "\n",
    "    metadata = {\n",
    "        \"target_offset\": target_positions,\n",
    "    }\n",
    "\n",
    "    datum[\"batch_correction_metadata\"] = metadata\n",
    "\n",
    "    return datum\n",
    "\n",
    "\n",
    "def inverse(predictions, metadata):\n",
    "    \"\"\"TODO: correct_predictions\"\"\"\n",
    "\n",
    "    # IMPORTANT: inputs are batched\n",
    "\n",
    "    # NOTE: Since we have only moved the positions, we can just leave them\n",
    "    # as is for training, but we'll need to revert them back to the original\n",
    "    # positions when we test against the dataset.\n",
    "\n",
    "    # Really, this should convert all the way back to the original, global\n",
    "    # positions, but that's a bit more effor. Leaving it as a TODO for now.\n",
    "    # thought: embed metadata in the data to know how to invert it:\n",
    "    # input, output, prediction_correction, batch_correction_metadata.\n",
    "    predictions = np.cumsum(predictions, axis=0)\n",
    "\n",
    "    predictions = homogenize_matrix(predictions)\n",
    "\n",
    "    # get the translation and rotation matrices\n",
    "    target_positions = metadata[\"target_offset\"][18]\n",
    "\n",
    "    # (30, 3) @ (3, 3) -> (30, 3)\n",
    "    predictions = predictions + target_positions\n",
    "\n",
    "    # dehomogenize the data\n",
    "    predictions = predictions[:, :2]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "    # # apply corrections needed by other transformations.\n",
    "    # return AgentCenter.prior_prediction_correction(batch_predictions, batch_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        \"\"\"TODO: init\"\"\"\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, \"*\"))\n",
    "        self.pkl_list.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"TODO: len\"\"\"\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"getitem\"\"\"\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "dataset = ArgoverseDataset(data_path=\"data/train\", transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm \n",
    "# # test loop through time\n",
    "\n",
    "# for datum in tqdm.tqdm(dataset):\n",
    "#     _ = apply(datum)\n",
    "\n",
    "# # using matmul for translation: 1:13, 1:14\n",
    "# # using addition for translation: 0:41, 0:33, clearly much better.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 151.68348694 2466.12939453]\n",
      " [ 151.58137512 2465.3894043 ]\n",
      " [ 151.59472656 2464.39868164]\n",
      " [ 151.56767273 2463.66186523]\n",
      " [ 151.54214478 2462.75317383]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[323], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(agent_index)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(datum[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp_out\u001b[39m\u001b[38;5;124m\"\u001b[39m][agent_index][:\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m datum_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(datum_transformed[\"p_out\"][agent_index][:5])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(datum_transformed[\"batch_correction_metadata\"][\"translation_transforms\"][0])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[320], line 131\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(datum)\u001b[0m\n\u001b[1;32m    128\u001b[0m positions \u001b[38;5;241m=\u001b[39m positions \u001b[38;5;241m-\u001b[39m target_positions\n\u001b[1;32m    130\u001b[0m first_offset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 131\u001b[0m offsets_h \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfirst_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43moffsets_h\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m offsets \u001b[38;5;241m=\u001b[39m offsets_h[:, :\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    133\u001b[0m positions[agent_index] \u001b[38;5;241m=\u001b[39m offsets\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/_core/shape_base.py:287\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    286\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m (arrs,)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "datum = dataset[100]\n",
    "agent_index = np.where(datum[\"track_id\"] == datum[\"agent_id\"])[0][0]\n",
    "# print(agent_index)\n",
    "print(datum[\"p_out\"][agent_index][:5])\n",
    "\n",
    "datum_transformed = apply(datum)\n",
    "# print(datum_transformed[\"p_out\"][agent_index][:5])\n",
    "\n",
    "# print(datum_transformed[\"batch_correction_metadata\"][\"translation_transforms\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 2)\n",
      "[[ 151.68348694 2466.12939453]\n",
      " [ 151.58137512 2465.3894043 ]\n",
      " [ 151.59472656 2464.39868164]\n",
      " [ 151.56767273 2463.66186523]\n",
      " [ 151.54214478 2462.75317383]]\n"
     ]
    }
   ],
   "source": [
    "predictions = datum_transformed[\"p_out\"][agent_index]\n",
    "metadata = datum_transformed[\"batch_correction_metadata\"]\n",
    "\n",
    "inversed = inverse(predictions, metadata)\n",
    "\n",
    "print(inversed.shape)\n",
    "print(inversed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
