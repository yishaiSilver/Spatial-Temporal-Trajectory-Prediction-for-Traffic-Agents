# # config.yaml
# data:
#   train_path: ./data/train
#   val_path: ./data/val_in
#   batch_size: 8
#   shuffle: true
#   num_workers: 8
#   transforms:
#     - AgentCenter
#   collate:
#     - p_in
#     # - v_in
#     # - lane

# # load data
# transform data
# collate data
# infer on data
# undo transform
# loss

num_epochs: 10

  # name: SimpleMLP
  # device: cuda
  # hidden_size: [4096, 2048, 4096, 2048, 4096, 1024]
  # dropout: 0.2

# model: 
#   name: SimpleRNN
#   device: cuda
#   hidden_size: [4096, 2048, 4096, 2048, 4096, 1024]
#   dropout: 0.2

# model: 
#   name: SimpleRNN
#   device: cuda
#   hidden_size: 512
#   num_layers: 4
#   dropout: 0.1

model: 
  name: Seq2Seq
  device: cuda
  hidden_size: 512
  num_layers: 5
  dropout: 0.1

optimizer:
  name: Adam
  params:
    lr: 0.0001
    weight_decay: 0.0

data:
  experimenting: 0 # set to 0 for full dataset
  
  # computer specific
  xps15:
    train_path: /media/ssilver/UbuntuShared/data/train
    val_path: /media/ssilver/UbuntuShared/data/val_in
    batch_size: 64
    shuffle: true
    num_workers: 10
    train_val_split: 0.9
  y520:
    train_path: ../train/train
    val_path: ../val_in/val_in
    batch_size: 32
    shuffle: true
    num_workers: 7
    train_val_split: 0.9
  acer:
    train_path: ../train/train
    val_path: ../val_in/val_in
    batch_size: 32
    shuffle: true
    num_workers: 7
    train_val_split: 0.9

  coord_dims: 2
  input_timesteps: 19
  output_timesteps: 30
  teacher_forcing_freq: 10
  features:
    lane:
      angle_filter: True # change to angle
      distance_filter: 10
      min_y_filter: -5
      num_points: 6
      embedding_size: 256
      positional_embeddings: 0 # not used if embedding_size > 0
    
    # needs work
    # lane: 0 # needs work
    p_in: 0
    v_in: 0 # should be same as p_in (num agents being considered)

    # fix me: positional embeddings causing NaN loss if too large
    positional_embeddings: 0 # 3 got down to 2.6

  transforms:
    - AgentCenter
    # - RandomNoise
