# # config.yaml
# data:
#   train_path: ./data/train
#   val_path: ./data/val_in
#   batch_size: 8
#   shuffle: true
#   num_workers: 8
#   transforms:
#     - AgentCenter
#   collate:
#     - p_in
#     # - v_in
#     # - lane

# # load data
# transform data
# collate data
# infer on data
# undo transform
# loss

num_epochs: 10

  # name: SimpleMLP
  # device: cuda
  # hidden_size: [4096, 2048, 4096, 2048, 4096, 1024]
  # dropout: 0.2

# model: 
#   name: SimpleRNN
#   device: cuda
#   hidden_size: [4096, 2048, 4096, 2048, 4096, 1024]
#   dropout: 0.2

model: 
  name: SimpleRNN
  device: cuda
  hidden_size: 512
  num_layers: 4
  dropout: 0.1

# config.yaml
data:
  experimenting: 0 # set to 0 for full dataset
  
  train_path: /media/ssilver/UbuntuShared/data/train
  val_path: /media/ssilver/UbuntuShared/data/val_in
  batch_size: 32
  shuffle: true
  num_workers: 12

  train_val_split: 0.9

  coord_dims: 2
  input_timesteps: 19
  output_timesteps: 30
  features:
    lane:
      angle_filter: True # change to angle
      distance_filter: 10
      num_lanes: 20
      embedding_size: 4
      positional_embeddings: 0 # not used if embedding_size > 0
    
    # needs work
    # lane: 0 # needs work
    p_in: 0
    v_in: 0 # should be same as p_in (num agents being considered)

    # fix me: positional embeddings causing NaN loss if too large
    positional_embeddings: 0 # 3 got down to 2.6

  transforms:
    - AgentCenter
    - RandomNoise
