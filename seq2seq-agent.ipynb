{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    city = [scene['city'] for scene in batch]\n",
    "    scene_idx = [scene['scene_idx'] for scene in batch]\n",
    "    agent_id = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    track_id = [scene['track_id'] for scene in batch]\n",
    "    pin = [scene['p_in'] for scene in batch]\n",
    "    vin = [scene['v_in'] for scene in batch]\n",
    "    pout = [scene['p_out'] for scene in batch]\n",
    "    vout = [scene['v_out'] for scene in batch]\n",
    "    lane = [scene['lane'] for scene in batch]\n",
    "    lane_norm = [scene['lane_norm'] for scene in batch]\n",
    "    \n",
    "    \n",
    "    return [city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm]\n",
    "\n",
    "\n",
    "def my_collate_for_csv(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    city = [scene['city'] for scene in batch]\n",
    "    scene_idx = [scene['scene_idx'] for scene in batch]\n",
    "    agent_id = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    track_id = [scene['track_id'] for scene in batch]\n",
    "    pin = [scene['p_in'] for scene in batch]\n",
    "    vin = [scene['v_in'] for scene in batch]\n",
    "    lane = [scene['lane'] for scene in batch]\n",
    "    lane_norm = [scene['lane_norm'] for scene in batch]\n",
    "    \n",
    "    \n",
    "    return [city, scene_idx, agent_id, car_mask, track_id, pin, vin, lane, lane_norm]\n",
    "\n",
    "def conv_pos_to_disp(x, last_known=None, use_known = False):\n",
    "    arr = np.zeros(x.shape)\n",
    "    for i in range(arr.shape[0]):\n",
    "        if not use_known:\n",
    "            for j in range(1, arr.shape[2]):\n",
    "                arr[i, :, j, :] = x[i, :, j, :] - x[i, :, j - 1, :]\n",
    "        else:\n",
    "            arr[i, :, 0, :] = x[i, :, 0, :] - last_known[i]\n",
    "            for j in range(1, arr.shape[2]):\n",
    "                arr[i, :, j, :] = x[i, :, j, :] - x[i, :, j - 1, :]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=8, num_layers=2, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_tracked = 4\n",
    "        \n",
    "        smallest = 128\n",
    "        \n",
    "        self.s1 = smallest\n",
    "        self.s2 = smallest * 2\n",
    "        self.s3 = smallest * 4\n",
    "        \n",
    "        self.lstm1 = nn.LSTMCell(input_size, self.s1)\n",
    "        self.lstm2 = nn.LSTMCell(self.s1, self.s2)\n",
    "        self.lstm3 = nn.LSTMCell(self.s2, self.s3)\n",
    "        \n",
    "        self.lstm4 = nn.LSTMCell(input_size, self.s1)\n",
    "        self.lstm5 = nn.LSTMCell(self.s1, self.s2)\n",
    "        self.lstm6 = nn.LSTMCell(self.s2, self.s3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.s3, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, input_size)\n",
    "        \n",
    "        self.fc4 = nn.Linear(self.s3, 256)\n",
    "        self.fc5 = nn.Linear(256, 256)\n",
    "        self.fc6 = nn.Linear(256, 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, future=0):\n",
    "        x = x.float()\n",
    "        outputs = []\n",
    "        n_samples = x.size(0)\n",
    "        \n",
    "        ht = torch.zeros(n_samples, self.s1, dtype=torch.float32).to(device)\n",
    "        ct = torch.zeros(n_samples, self.s1, dtype=torch.float32).to(device)\n",
    "        ht2 = torch.zeros(n_samples, self.s2, dtype=torch.float32).to(device)\n",
    "        ct2 = torch.zeros(n_samples, self.s2, dtype=torch.float32).to(device)\n",
    "        ht3 = torch.zeros(n_samples, self.s3, dtype=torch.float32).to(device)\n",
    "        ct3 = torch.zeros(n_samples, self.s3, dtype=torch.float32).to(device)\n",
    "        \n",
    "        for input_t in x.split(1, dim=1):\n",
    "            input_t = input_t.reshape((n_samples, self.input_size))\n",
    "            ht, ct = self.lstm1(input_t, (ht, ct))\n",
    "            ht2, ct2 = self.lstm2(ht, (ht2, ct2))\n",
    "            ht3, ct3 = self.lstm3(ht2, (ht3, ct3))\n",
    "            \n",
    "        ret = input_t\n",
    "        for i in range(future):\n",
    "            ht, ct = self.lstm4(ret, (ht, ct))\n",
    "            ht2, ct2 = self.lstm5(ht, (ht2, ct2))\n",
    "            ht3, ct3 = self.lstm6(ht2, (ht3, ct3))\n",
    "                                 \n",
    "            ret = F.relu(self.fc1(ht3))\n",
    "            ret = F.relu(self.fc2(ret))\n",
    "            ret = self.fc3(ret)\n",
    "            \n",
    "            out = F.relu(self.fc4(ht3))\n",
    "            out = F.relu(self.fc5(out))\n",
    "            out = self.fc6(out)\n",
    "            outputs.append(out)\n",
    "            \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "#     model = RNN().to(device)\n",
    "#     model.load_state_dict(torch.load(\"MODEL\"))\n",
    "    model.train()\n",
    "    \n",
    "    num_tracked = model.num_tracked\n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    \n",
    "    total = 0\n",
    "    count = 0\n",
    "    for batch_idx, batch in enumerate(iterator):\n",
    "        city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm = batch\n",
    "        pin = np.array(pin)\n",
    "        pout = np.array(pout)\n",
    "        vin = np.array(vin)\n",
    "        vout = np.array(vout)\n",
    "        car_mask = np.count_nonzero(np.array(car_mask))\n",
    "        \n",
    "        last_known = pin[:, :, 18, :]\n",
    "    \n",
    "        din = conv_pos_to_disp(pin)\n",
    "        dout = conv_pos_to_disp(pout, last_known, True)\n",
    "        \n",
    "        inp = np.zeros((len(agent_id), num_tracked, 19, 2))\n",
    "        outp = np.zeros((len(agent_id), 30, 2))\n",
    "        for i in range(len(agent_id)):\n",
    "            agent_index = np.where(track_id[i] == agent_id[i])[0][0]\n",
    "            \n",
    "            dx = pin[i, :, 18, 0] - pin[i, agent_index, 18, 0]\n",
    "            dy = pin[i, :, 18, 1] - pin[i, agent_index, 18, 1]\n",
    "            ds = (dx**2 + dy**2) ** 0.5\n",
    "            \n",
    "            closest = np.argsort(ds)\n",
    "            \n",
    "            rin = pin[i, :, :, :] - pin[i, agent_index, :, :]\n",
    "#             rout = pout[i, :, :, :] - pout[i, agent_index, :, :]\n",
    "            \n",
    "            inp[i, 0] = din[i, agent_index]\n",
    "            outp[i] = dout[i, agent_index]\n",
    "            for j in range(1, num_tracked):\n",
    "#                 inp[i, j] = din[i, agent_index]\n",
    "                if closest[j] >= car_mask:\n",
    "                    break\n",
    "                inp[i, j] = rin[closest[j]]\n",
    "                \n",
    "#                 outp[i, j] = rout[closest[j]]\n",
    "        \n",
    "        inp = inp.reshape((len(agent_id), 19, 2*num_tracked))\n",
    "        outp = outp.reshape((len(agent_id), 60*1))\n",
    "    \n",
    "        data = torch.from_numpy(inp)\n",
    "        target = torch.from_numpy(outp)\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, 30)\n",
    "\n",
    "        target = target.float()\n",
    "        \n",
    "        loss = nn.MSELoss()(output, target)\n",
    "        \n",
    "        eps = 1e-6\n",
    "        rmse = torch.sqrt(loss + eps)\n",
    "        RMSE.append(rmse.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "        total += loss.item()\n",
    "        count += 1\n",
    "        iterator.set_postfix_str(\"loss={}, avg.={}\".format(loss.item(), total/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "#     model = RNN().to(device)\n",
    "#     model.load_state_dict(torch.load(\"MODEL\"))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_dist = 0\n",
    "    num_tested = 0\n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm(test_loader, total=int(100))\n",
    "        for batch_idx, batch in enumerate(iterator):\n",
    "            \n",
    "            if num_tested >= 100:\n",
    "                break;\n",
    "            \n",
    "            city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm = batch\n",
    "            pin = np.array(pin)\n",
    "            pout = np.array(pout)\n",
    "            vin = np.array(vin)\n",
    "            vout = np.array(vout)\n",
    "            car_mask = np.array(car_mask)\n",
    "        \n",
    "        \n",
    "            last_known = pin[:, :, 18, :]\n",
    "            pin = conv_pos_to_disp(pin)\n",
    "            pout = conv_pos_to_disp(pout, last_known, True)\n",
    "\n",
    "            pin = pin.reshape((len(agent_id), 19, 120))\n",
    "            pout = pout.reshape((len(agent_id), 3600)) # 30x120\n",
    "\n",
    "            data = torch.from_numpy(pin)\n",
    "            target = torch.from_numpy(pout)\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data, 30)\n",
    "            \n",
    "            target = target.float()\n",
    "            \n",
    "            num_tested += 1\n",
    "            test_loss += nn.MSELoss()(output, target).item() # sum up batch loss\n",
    "            \n",
    "    test_loss /= num_tested\n",
    "    print(\"Test loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/2060 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2060\n",
      "EPOCH: 1 -----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1019/2060 [08:15<10:13,  1.70it/s, loss=0.16101738810539246, avg.=0.26574849438971465]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fdace851940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yishai/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/yishai/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      " 49%|████▉     | 1019/2060 [08:18<08:29,  2.04it/s, loss=0.16101738810539246, avg.=0.26574849438971465]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c4ba89c7cf46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH: {} -----------------------------------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;31m#     test(model, device, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-205a0687c3cd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mRMSE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "device = \"cuda\"\n",
    "model = RNN().to(device) #using cpu here\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "batch_sz = 100\n",
    "num_epoch = 10\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "\n",
    "new_path = \"./new_train/new_train/\"\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "dataset_len = len(val_dataset)\n",
    "indices = np.arange(0, len(val_dataset))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# train_loader = DataLoader(val_dataset, batch_size=batch_sz, collate_fn=my_collate, num_workers=1,\n",
    "#                          sampler=torch.utils.data.SubsetRandomSampler(indices[:int(dataset_len*0.8)]))\n",
    "# test_loader = DataLoader(val_dataset, batch_size=batch_sz, collate_fn=my_collate, num_workers=1,\n",
    "#                         sampler=torch.utils.data.SubsetRandomSampler(indices[int(dataset_len*0.8):]))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=my_collate, num_workers=4)\n",
    "test_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle=True, collate_fn=my_collate, num_workers=4)\n",
    "\n",
    "print(len(train_loader))\n",
    "\n",
    "# do_both(model, device, train_loader, test_loader, optimizer, epoch)\n",
    "\n",
    "PATH = \"seq2seq-neighbors.pth\"\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# validation_err = 10000\n",
    "# num_valids_wrong = 0\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    print(\"EPOCH: {} -----------------------------------\".format(epoch))\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "#     test(model, device, test_loader)\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_disp_to_pos(x, last_known):\n",
    "#     print(\"cdtp: {}\".format(x.shape))\n",
    "    x[0, :] += last_known\n",
    "    for i in range(1, 30):\n",
    "        x[i, :] += x[i - 1, :]\n",
    "    return x\n",
    "\n",
    "def create_csv_for_vals(model, device, loader):#     model = RNN().to(device)\n",
    "    with open('csv_submission.csv', 'w') as csv_sub_wrap:\n",
    "        csv_sub = csv.writer(csv_sub_wrap)\n",
    "        \n",
    "        first_row = [\"ID\",  \"v1\",  \"v2\",  \"v3\",  \"v4\",  \"v5\",  \"v6\",  \"v7\",  \"v8\",  \"v9\",  \"v10\",  \"v11\",  \"v12\",  \"v13\",  \"v14\",  \"v15\",  \"v16\",  \"v17\",  \"v18\",  \"v19\",  \"v20\",  \"v21\",  \"v22\",  \"v23\",  \"v24\",  \"v25\",  \"v26\",  \"v27\",  \"v28\",  \"v29\",  \"v30\",  \"v31\",  \"v32\",  \"v33\",  \"v34\",  \"v35\",  \"v36\",  \"v37\",  \"v38\",  \"v39\",  \"v40\",  \"v41\",  \"v42\",  \"v43\",  \"v44\",  \"v45\",  \"v46\",  \"v47\",  \"v48\",  \"v49\",  \"v50\",  \"v51\",  \"v52\",  \"v53\",  \"v54\",  \"v55\",  \"v56\",  \"v57\",  \"v58\",  \"v59\",  \"v60\"]\n",
    "        csv_sub.writerow(first_row)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            iterator = tqdm(loader, total=int(len(loader)))\n",
    "            for batch_idx, batch in enumerate(iterator):\n",
    "                city, scene_idx, agent_id, car_mask, track_id, pin, vin, lane, lane_norm = batch\n",
    "                pin = np.array(pin)\n",
    "\n",
    "                pin2 = pin\n",
    "                pin = conv_pos_to_disp(pin)\n",
    "\n",
    "                pin = pin.reshape((len(agent_id), 19, 120))\n",
    "\n",
    "                data = torch.from_numpy(pin)\n",
    "\n",
    "                data = data.to(device)\n",
    "                output = model(data, 30)\n",
    "\n",
    "                output = output.reshape((len(agent_id), 60, 30, 2)).cpu().numpy()                \n",
    "\n",
    "                for i in range(len(agent_id)):\n",
    "                    agent_index = np.where(track_id[i] == agent_id[i])[0][0]\n",
    "                    last_known = pin2[i, agent_index, 18, :]\n",
    "#                     print(last_known)\n",
    "                    pout = conv_disp_to_pos(output[i, agent_index, :, :], last_known)\n",
    "                    pout = pout.reshape((60))\n",
    "                    out = []\n",
    "                    for j in range(61):\n",
    "                        out.append(1)\n",
    "                    out[0] = scene_idx[i]\n",
    "                    out[1:] = pout\n",
    "                    csv_sub.writerow(out)\n",
    "#                     csv_sub.writerow([scene_idx[i], pout])\n",
    "#                     csv_sub.write(scene_idx)\n",
    "#                     csv_sub.writerow(pout)\n",
    "\n",
    "def visualize(model, device, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm(loader, total=int(len(loader)))\n",
    "        for batch_idx, batch in enumerate(iterator):\n",
    "            city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm = batch\n",
    "            pin = np.array(pin)\n",
    "\n",
    "            pin2 = pin\n",
    "            pin = conv_pos_to_disp(pin)\n",
    "\n",
    "            pin = pin.reshape((len(agent_id), 19, 120))\n",
    "\n",
    "            data = torch.from_numpy(pin)\n",
    "\n",
    "            data = data.to(device)\n",
    "            output = model(data, 30)\n",
    "\n",
    "            output = output.reshape((len(agent_id), 60, 30, 2)).cpu().numpy()                \n",
    "                \n",
    "            \n",
    "            batch_sz = len(agent_id)\n",
    "            fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "            fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "            axs = axs.ravel()   \n",
    "            for i in range(batch_sz):\n",
    "                axs[i].xaxis.set_ticks([])\n",
    "                axs[i].yaxis.set_ticks([])\n",
    "                \n",
    "                agent_index = np.where(track_id[i] == agent_id[i])[0][0]\n",
    "                last_known = pin2[i, agent_index, 18, :]\n",
    "#                     print(last_known)\n",
    "                pred = conv_disp_to_pos(output[i, agent_index, :, :], last_known)\n",
    "\n",
    "                # first two feature dimensions are (x,y) positions\n",
    "                axs[i].scatter(pin2[i, agent_id[i],:,0], pin2[i, agent_id[i],:,1])\n",
    "                axs[i].scatter(pout[i, agent_id[i],:,0], pout[i, agent_id[i],:,1])\n",
    "                axs[i].scatter(pred[i, agent_id[i],:,0], pred[i, agent_id[i],:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "device = \"cuda\"\n",
    "model = RNN().to(device) #using cpu here\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_sz = 2\n",
    "num_epoch = 10\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# new_path = \"./new_val_in/new_val_in/\"\n",
    "\n",
    "# val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "# dataset_len = len(val_dataset)\n",
    "# indices = np.arange(0, len(val_dataset))\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "# loader = DataLoader(val_dataset, batch_size=batch_sz, collate_fn=my_collate_for_csv, num_workers=1)\n",
    "\n",
    "\n",
    "new_path = \"./new_train/new_train/\"\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "train_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=my_collate, num_workers=1)\n",
    "\n",
    "\n",
    "# do_both(model, device, train_loader, test_loader, optimizer, epoch)\n",
    "PATH = \"RNN-Linear-v02(big boi).pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "visualize(model, device, train_loader)\n",
    "\n",
    "# create_csv_for_vals(model, device, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RMSE_out = np.array(RMSE)\n",
    "ones = np.ones((len(RMSE)))\n",
    "\n",
    "RMSE_out = np.minimum(RMSE_out, ones)\n",
    "\n",
    "plt.plot(RMSE_out)\n",
    "plt.savefig('RNN-RMSE.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
