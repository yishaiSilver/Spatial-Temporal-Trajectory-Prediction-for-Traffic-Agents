{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    city = [scene['city'] for scene in batch]\n",
    "    scene_idx = [scene['scene_idx'] for scene in batch]\n",
    "    agent_id = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    track_id = [scene['track_id'] for scene in batch]\n",
    "    pin = [scene['p_in'] for scene in batch]\n",
    "    vin = [scene['v_in'] for scene in batch]\n",
    "    pout = [scene['p_out'] for scene in batch]\n",
    "    vout = [scene['v_out'] for scene in batch]\n",
    "    lane = [scene['lane'] for scene in batch]\n",
    "    lane_norm = [scene['lane_norm'] for scene in batch]\n",
    "    \n",
    "    \n",
    "    return [city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm]\n",
    "\n",
    "\n",
    "def my_collate_for_csv(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    city = [scene['city'] for scene in batch]\n",
    "    scene_idx = [scene['scene_idx'] for scene in batch]\n",
    "    agent_id = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    track_id = [scene['track_id'] for scene in batch]\n",
    "    pin = [scene['p_in'] for scene in batch]\n",
    "    vin = [scene['v_in'] for scene in batch]\n",
    "    lane = [scene['lane'] for scene in batch]\n",
    "    lane_norm = [scene['lane_norm'] for scene in batch]\n",
    "    \n",
    "    \n",
    "    return [city, scene_idx, agent_id, car_mask, track_id, pin, vin, lane, lane_norm]\n",
    "\n",
    "def conv_pos_to_disp(x, last_known=None, use_known = False):\n",
    "    arr = np.zeros(x.shape)\n",
    "    for i in range(arr.shape[0]):\n",
    "        if not use_known:\n",
    "            for j in range(1, arr.shape[2]):\n",
    "                arr[i, :, j, :] = x[i, :, j, :] - x[i, :, j - 1, :]\n",
    "        else:\n",
    "            arr[i, :, 0, :] = x[i, :, 0, :] - last_known[i]\n",
    "            for j in range(1, arr.shape[2]):\n",
    "                arr[i, :, j, :] = x[i, :, j, :] - x[i, :, j - 1, :]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=2, num_layers=2, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.s1 = 64\n",
    "        self.s2 = 128\n",
    "        self.s3 = 256\n",
    "        \n",
    "        self.lstm1 = nn.LSTMCell(input_size, self.s1)\n",
    "        self.lstm2 = nn.LSTMCell(self.s1, self.s2)\n",
    "        self.lstm3 = nn.LSTMCell(self.s2, self.s3)\n",
    "        \n",
    "        self.lstm4 = nn.LSTMCell(input_size, self.s1)\n",
    "        self.lstm5 = nn.LSTMCell(self.s1, self.s2)\n",
    "        self.lstm6 = nn.LSTMCell(self.s2, self.s3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.s3, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, input_size)\n",
    "        \n",
    "    def forward(self, x, future=0):\n",
    "        x = x.float()\n",
    "        outputs = []\n",
    "        n_samples = x.size(0)\n",
    "        \n",
    "        ht = torch.zeros(n_samples, self.s1, dtype=torch.float32).to(device)\n",
    "        ct = torch.zeros(n_samples, self.s1, dtype=torch.float32).to(device)\n",
    "        ht2 = torch.zeros(n_samples, self.s2, dtype=torch.float32).to(device)\n",
    "        ct2 = torch.zeros(n_samples, self.s2, dtype=torch.float32).to(device)\n",
    "        ht3 = torch.zeros(n_samples, self.s3, dtype=torch.float32).to(device)\n",
    "        ct3 = torch.zeros(n_samples, self.s3, dtype=torch.float32).to(device)\n",
    "        \n",
    "        for input_t in x.split(1, dim=1):\n",
    "            input_t = input_t.reshape((n_samples, self.input_size))\n",
    "            ht, ct = self.lstm1(input_t, (ht, ct))\n",
    "            ht2, ct2 = self.lstm2(ht, (ht2, ct2))\n",
    "            ht3, ct3 = self.lstm3(ht2, (ht3, ct3))\n",
    "        \n",
    "        for i in range(future):\n",
    "            ht, ct = self.lstm4(input_t, (ht, ct))\n",
    "            ht2, ct2 = self.lstm5(ht, (ht2, ct2))\n",
    "            ht3, ct3 = self.lstm6(ht2, (ht3, ct3))\n",
    "                                      \n",
    "            out = F.relu(self.fc1(ht3))\n",
    "            out = F.relu(self.fc2(out))\n",
    "            out = self.fc3(out)\n",
    "            outputs.append(out)\n",
    "            \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from tqdm import tqdm_notebook as tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "#     model = RNN().to(device)\n",
    "#     model.load_state_dict(torch.load(\"MODEL\"))\n",
    "    model.train()\n",
    "    iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    \n",
    "    total = 0\n",
    "    count = 0\n",
    "    for batch_idx, batch in enumerate(iterator):\n",
    "        city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm = batch\n",
    "        pin = np.array(pin)\n",
    "        pout = np.array(pout)\n",
    "        vin = np.array(vin)\n",
    "        vout = np.array(vout)\n",
    "        car_mask = np.array(car_mask)\n",
    "            \n",
    "        last_known = pin[:, :, 18, :]\n",
    "        pin = conv_pos_to_disp(pin)\n",
    "        pout = conv_pos_to_disp(pout, last_known, True)\n",
    "        \n",
    "        inp = np.zeros((len(agent_id), 19, 2))\n",
    "        outp = np.zeros((len(agent_id), 1, 30, 2))\n",
    "        for i in range(len(agent_id)):\n",
    "            agent_index = np.where(track_id[i] == agent_id[i])[0][0]\n",
    "            \n",
    "            inp[i] = pin[i, agent_index]\n",
    "            outp[i] = pout[i, agent_index]\n",
    "            \n",
    "#         pin = pin.reshape((len(agent_id), 19, 120))\n",
    "#         pout = pout.reshape((len(agent_id), 3600))\n",
    "        \n",
    "#         inp = inp.reshape((len(agent)))\n",
    "        outp = outp.reshape((len(agent_id), 60))\n",
    "    \n",
    "        data = torch.from_numpy(inp)\n",
    "        target = torch.from_numpy(outp)\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, 30)\n",
    "\n",
    "        target = target.float()\n",
    "        \n",
    "        loss = nn.MSELoss()(output, target)\n",
    "        \n",
    "        eps = 1e-6\n",
    "        rmse = torch.sqrt(loss + eps)\n",
    "        RMSE.append(rmse.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        total += loss.item()\n",
    "        count += 1\n",
    "        iterator.set_postfix_str(\"loss={}, avg.={}\".format(loss.item(), total/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "#     model = RNN().to(device)\n",
    "#     model.load_state_dict(torch.load(\"MODEL\"))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_dist = 0\n",
    "    num_tested = 0\n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm(test_loader, total=int(100))\n",
    "        for batch_idx, batch in enumerate(iterator):\n",
    "            \n",
    "            if num_tested >= 100:\n",
    "                break;\n",
    "            \n",
    "            city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm = batch\n",
    "            pin = np.array(pin)\n",
    "            pout = np.array(pout)\n",
    "            vin = np.array(vin)\n",
    "            vout = np.array(vout)\n",
    "            car_mask = np.array(car_mask)\n",
    "        \n",
    "        \n",
    "            last_known = pin[:, :, 18, :]\n",
    "            pin = conv_pos_to_disp(pin)\n",
    "            pout = conv_pos_to_disp(pout, last_known, True)\n",
    "\n",
    "            pin = pin.reshape((len(agent_id), 19, 120))\n",
    "            pout = pout.reshape((len(agent_id), 3600)) # 30x120\n",
    "\n",
    "            data = torch.from_numpy(pin)\n",
    "            target = torch.from_numpy(pout)\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data, 30)\n",
    "            \n",
    "            target = target.float()\n",
    "            \n",
    "            num_tested += 1\n",
    "            test_loss += nn.MSELoss()(output, target).item() # sum up batch loss\n",
    "            \n",
    "    test_loss /= num_tested\n",
    "    print(\"Test loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/2060 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2060\n",
      "EPOCH: 1 -----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–Œ                           | 42/2060 [01:13<59:23,  1.77s/it, loss=0.22648201882839203, avg.=0.35685907517160687]"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "device = \"cpu\"\n",
    "model = RNN().to(device) #using cpu here\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_sz = 100\n",
    "num_epoch = 10\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "\n",
    "new_path = \"./new_train/new_train/\"\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "dataset_len = len(val_dataset)\n",
    "indices = np.arange(0, len(val_dataset))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# train_loader = DataLoader(val_dataset, batch_size=batch_sz, collate_fn=my_collate, num_workers=1,\n",
    "#                          sampler=torch.utils.data.SubsetRandomSampler(indices[:int(dataset_len*0.8)]))\n",
    "# test_loader = DataLoader(val_dataset, batch_size=batch_sz, collate_fn=my_collate, num_workers=1,\n",
    "#                         sampler=torch.utils.data.SubsetRandomSampler(indices[int(dataset_len*0.8):]))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=my_collate, num_workers=0)\n",
    "test_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle=True, collate_fn=my_collate, num_workers=0)\n",
    "\n",
    "print(len(train_loader))\n",
    "\n",
    "# do_both(model, device, train_loader, test_loader, optimizer, epoch)\n",
    "\n",
    "PATH = \"RNN-Linear-v02(big boi).pth\"\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# validation_err = 10000\n",
    "# num_valids_wrong = 0\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    print(\"EPOCH: {} -----------------------------------\".format(epoch))\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "#     test(model, device, test_loader)\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_disp_to_pos(x, last_known):\n",
    "#     print(\"cdtp: {}\".format(x.shape))\n",
    "    x[0, :] += last_known\n",
    "    for i in range(1, 30):\n",
    "        x[i, :] += x[i - 1, :]\n",
    "    return x\n",
    "\n",
    "def create_csv_for_vals(model, device, loader):#     model = RNN().to(device)\n",
    "    with open('csv_submission.csv', 'w') as csv_sub_wrap:\n",
    "        csv_sub = csv.writer(csv_sub_wrap)\n",
    "        \n",
    "        first_row = [\"ID\",  \"v1\",  \"v2\",  \"v3\",  \"v4\",  \"v5\",  \"v6\",  \"v7\",  \"v8\",  \"v9\",  \"v10\",  \"v11\",  \"v12\",  \"v13\",  \"v14\",  \"v15\",  \"v16\",  \"v17\",  \"v18\",  \"v19\",  \"v20\",  \"v21\",  \"v22\",  \"v23\",  \"v24\",  \"v25\",  \"v26\",  \"v27\",  \"v28\",  \"v29\",  \"v30\",  \"v31\",  \"v32\",  \"v33\",  \"v34\",  \"v35\",  \"v36\",  \"v37\",  \"v38\",  \"v39\",  \"v40\",  \"v41\",  \"v42\",  \"v43\",  \"v44\",  \"v45\",  \"v46\",  \"v47\",  \"v48\",  \"v49\",  \"v50\",  \"v51\",  \"v52\",  \"v53\",  \"v54\",  \"v55\",  \"v56\",  \"v57\",  \"v58\",  \"v59\",  \"v60\"]\n",
    "        csv_sub.writerow(first_row)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            iterator = tqdm(loader, total=int(len(loader)))\n",
    "            for batch_idx, batch in enumerate(iterator):\n",
    "                city, scene_idx, agent_id, car_mask, track_id, pin, vin, lane, lane_norm = batch\n",
    "                pin = np.array(pin)\n",
    "\n",
    "                pin2 = pin\n",
    "                pin = conv_pos_to_disp(pin)\n",
    "\n",
    "                pin = pin.reshape((len(agent_id), 19, 120))\n",
    "\n",
    "                data = torch.from_numpy(pin)\n",
    "\n",
    "                data = data.to(device)\n",
    "                output = model(data, 30)\n",
    "\n",
    "                output = output.reshape((len(agent_id), 60, 30, 2)).cpu().numpy()                \n",
    "\n",
    "                for i in range(len(agent_id)):\n",
    "                    agent_index = np.where(track_id[i] == agent_id[i])[0][0]\n",
    "                    last_known = pin2[i, agent_index, 18, :]\n",
    "#                     print(last_known)\n",
    "                    pout = conv_disp_to_pos(output[i, agent_index, :, :], last_known)\n",
    "                    pout = pout.reshape((60))\n",
    "                    out = []\n",
    "                    for j in range(61):\n",
    "                        out.append(1)\n",
    "                    out[0] = scene_idx[i]\n",
    "                    out[1:] = pout\n",
    "                    csv_sub.writerow(out)\n",
    "#                     csv_sub.writerow([scene_idx[i], pout])\n",
    "#                     csv_sub.write(scene_idx)\n",
    "#                     csv_sub.writerow(pout)\n",
    "\n",
    "def visualize(model, device, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm(loader, total=int(len(loader)))\n",
    "        for batch_idx, batch in enumerate(iterator):\n",
    "            city, scene_idx, agent_id, car_mask, track_id, pin, vin, pout, vout, lane, lane_norm = batch\n",
    "            pin = np.array(pin)\n",
    "\n",
    "            pin2 = pin\n",
    "            pin = conv_pos_to_disp(pin)\n",
    "\n",
    "            pin = pin.reshape((len(agent_id), 19, 120))\n",
    "\n",
    "            data = torch.from_numpy(pin)\n",
    "\n",
    "            data = data.to(device)\n",
    "            output = model(data, 30)\n",
    "\n",
    "            output = output.reshape((len(agent_id), 60, 30, 2)).cpu().numpy()                \n",
    "                \n",
    "            \n",
    "            batch_sz = len(agent_id)\n",
    "            fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "            fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "            axs = axs.ravel()   \n",
    "            for i in range(batch_sz):\n",
    "                axs[i].xaxis.set_ticks([])\n",
    "                axs[i].yaxis.set_ticks([])\n",
    "                \n",
    "                agent_index = np.where(track_id[i] == agent_id[i])[0][0]\n",
    "                last_known = pin2[i, agent_index, 18, :]\n",
    "#                     print(last_known)\n",
    "                pred = conv_disp_to_pos(output[i, agent_index, :, :], last_known)\n",
    "\n",
    "                # first two feature dimensions are (x,y) positions\n",
    "                axs[i].scatter(pin2[i, agent_id[i],:,0], pin2[i, agent_id[i],:,1])\n",
    "                axs[i].scatter(pout[i, agent_id[i],:,0], pout[i, agent_id[i],:,1])\n",
    "                axs[i].scatter(pred[i, agent_id[i],:,0], pred[i, agent_id[i],:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "device = \"cuda\"\n",
    "model = RNN().to(device) #using cpu here\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "batch_sz = 2\n",
    "num_epoch = 10\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# new_path = \"./new_val_in/new_val_in/\"\n",
    "\n",
    "# val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "# dataset_len = len(val_dataset)\n",
    "# indices = np.arange(0, len(val_dataset))\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "# loader = DataLoader(val_dataset, batch_size=batch_sz, collate_fn=my_collate_for_csv, num_workers=1)\n",
    "\n",
    "\n",
    "new_path = \"./new_train/new_train/\"\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "train_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=my_collate, num_workers=1)\n",
    "\n",
    "\n",
    "# do_both(model, device, train_loader, test_loader, optimizer, epoch)\n",
    "PATH = \"RNN-Linear-v02(big boi).pth\"\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "visualize(model, device, train_loader)\n",
    "\n",
    "# create_csv_for_vals(model, device, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RMSE_out = np.array(RMSE)\n",
    "ones = np.ones((len(RMSE)))\n",
    "\n",
    "RMSE_out = np.minimum(RMSE_out, ones)\n",
    "\n",
    "plt.plot(RMSE_out)\n",
    "plt.savefig('RNN-RMSE.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
